setwd("~/ec50/lab8")
rm(list=ls()) # removes all objects from the environment
cat('\014') # clears the console
setwd("~/ec50/lab8")
#Set seed for cross validation and random forests
HUID <- 21423505 #Replace with your HUID
set.seed(HUID)
# Install packages (if necessary) and load required libraries
if (!require(haven)) install.packages("haven"); library(haven)
if (!require(randomForest)) install.packages("randomForest"); library(randomForest)
if (!require(tidyverse)) install.packages("tidyverse"); library(tidyverse)
#Open stata data set
dat <- read_dta("health.dta")
head(dat)
#Store health variables from time t-1 which all end with _tm
all_predictors <- colnames(dat[,grep("^[tm1]", names(dat))])
all_predictors
#Store predictor variables which all start with P_*, but EXCLUDE race
race <- c("tm1_dem_black")
exclude_race <- setdiff(all_predictors,race)
exclude_race
#Define training and test data sets
#Use a uniformly distributed random number between 0 and 1
dat$random_number <- runif(length(dat$patient_id))
## Generate a training flag for 10% of the sample
dat$train_flag <- ifelse(dat$random_number<= 0.1, 1, 0)
#Report number of observations in training and test samples
sum(dat$train_flag)
sum(1-dat$train_flag)
#Data frame with training data (randomly selected 10% of the data)
training <- subset(dat, train_flag == 1)
summary(training)
#Data frame with test data (remaining 90% of the data)
test <- subset(dat, train_flag == 0)
summary(test)
#Reformulate allows us to write yvar ~ xvar1 + xvar2 + ... using a list of all
#the variables without writing them out
mod1 <- randomForest(reformulate(exclude_race, "cost_t"),
ntree=100,
mtry=149,
importance=TRUE, ## add importance=TRUE so that we store the variable importance information
data=training)
#Tuning parameters are ntree and mtry
#ntree is number of trees in your forest
#mtry is the number of predictors considered at each split (default is number of predictors divided by 3)
### Try changing mtry and ntree
mod1 #Review the Random Forest Results
### generate predictions for all observations in test and training samples
y_test_predictions_mod1 <- predict(mod1, newdata=test)
y_train_predictions_mod1 <- predict(mod1, newdata=training)
#Variable importance
importance(mod1)
varImpPlot(mod1, type=1) #Plot the Random Forest Results
dev.copy(png,'mod1_importance.png')
dev.off()
mod2 <- randomForest(reformulate(all_predictors, "cost_t"),
ntree=100,
mtry=150,
importance=TRUE, ## add importance=TRUE so that we store the variable importance information
data=training)
#Tuning parameters are ntree and mtry
#ntree is number of trees in your forest
#mtry is the number of predictors considered at each split (default is number of predictors divided by 3)
### Try changing mtry and ntree
mod2 #Review the Random Forest Results
### generate predictions for all observations in test and training samples
y_train_predictions_mod2 <- predict(mod2, newdata=training)
y_test_predictions_mod2 <- predict(mod2, newdata=test)
#Variable importance
importance(mod2)
varImpPlot(mod2, type=1) #Plot the Random Forest Results
dev.copy(png,'mod2_importance.png')
dev.off()
#Reformulate allows us to write yvar ~ xvar1 + xvar2 + ... using a list of all
#the variables without writing them out
mod3 <- randomForest(reformulate(exclude_race, "gagne_sum_t"),
ntree=100,
mtry=149,
importance=TRUE, ## add importance=TRUE so that we store the variable importance information
data=training)
#Tuning parameters are ntree and mtry
#ntree is number of trees in your forest
#mtry is the number of predictors considered at each split (default is number of predictors divided by 3)
### Try changing mtry and ntree
mod3 #Review the Random Forest Results
### generate predictions for all observations in test and training samples
y_test_predictions_mod3 <- predict(mod3, newdata=test)
y_train_predictions_mod3 <- predict(mod3, newdata=training)
#Variable importance
importance(mod3)
varImpPlot(mod3, type=1) #Plot the Random Forest Results
dev.copy(png,'mod3_importance.png')
dev.off()
#type	is either 1 or 2, specifying the type of importance measure
#(1=mean decrease in accuracy, 2=mean decrease in node impurity)
#-------------------------------------------------------------------------------
# Model 4: Random forest trained to predict health, using all predictors,
# INCLUDING patient's race
#-------------------------------------------------------------------------------
#Reformulate allows us to write yvar ~ xvar1 + xvar2 + ... using a list of all
#the variables without writing them out
mod4 <- randomForest(reformulate(all_predictors, "gagne_sum_t"),
ntree=100,
mtry=150,
importance=TRUE, ## add importance=TRUE so that we store the variable importance information
data=training)
#Tuning parameters are ntree and mtry
#ntree is number of trees in your forest
#mtry is the number of predictors considered at each split (default is number of predictors divided by 3)
### Try changing mtry and ntree
mod4 #Review the Random Forest Results
### generate predictions for all observations in test and training samples
y_train_predictions_mod4 <- predict(mod4, newdata=training)
y_test_predictions_mod4 <- predict(mod4, newdata=test)
#Variable importance
importance(mod4)
varImpPlot(mod4, type=1) #Plot the Random Forest Results
dev.copy(png,'mod4_importance.png')
dev.off()
#type	is either 1 or 2, specifying the type of importance measure
#(1=mean decrease in accuracy, 2=mean decrease in node impurity)
mod5 <- randomForest(reformulate(exclude_race, "cost_avoidance_t"),
ntree=100,
mtry=150,
importance=TRUE, ## add importance=TRUE so that we store the variable importance information
data=training)
mod5 #Review the Random Forest Results
### generate predictions for all observations in test and training samples
y_train_predictions_mod5 <- predict(mod5, newdata=training)
y_test_predictions_mod5 <- predict(mod5, newdata=test)
#Variable importance
importance(mod5)
varImpPlot(mod5, type=1) #Plot the Random Forest Results
dev.copy(png,'mod5_importance.png')
dev.off()
mod6 <- randomForest(reformulate(all_predictors, "cost_avoidance_t"),
ntree=100,
mtry=150,
importance=TRUE, ## add importance=TRUE so that we store the variable importance information
data=training)
mod6 #Review the Random Forest Results
### generate predictions for all observations in test and training samples
y_train_predictions_mod6 <- predict(mod6, newdata=training)
y_test_predictions_mod6 <- predict(mod6, newdata=test)
#Variable importance
importance(mod6)
varImpPlot(mod6, type=1) #Plot the Random Forest Results
dev.copy(png,'mod6_importance.png')
dev.off()
importance(mod6)
mod5 <- randomForest(reformulate(exclude_race, "cost_avoidable_t"),
ntree=100,
mtry=150,
importance=TRUE, ## add importance=TRUE so that we store the variable importance information
data=training)
mod5 #Review the Random Forest Results
### generate predictions for all observations in test and training samples
y_train_predictions_mod5 <- predict(mod5, newdata=training)
y_test_predictions_mod5 <- predict(mod5, newdata=test)
#Variable importance
importance(mod5)
varImpPlot(mod5, type=1) #Plot the Random Forest Results
dev.copy(png,'mod5_importance.png')
dev.off()
mod6 <- randomForest(reformulate(all_predictors, "cost_avoidable_t"),
ntree=100,
mtry=150,
importance=TRUE, ## add importance=TRUE so that we store the variable importance information
data=training)
mod6 #Review the Random Forest Results
### generate predictions for all observations in test and training samples
y_train_predictions_mod6 <- predict(mod6, newdata=training)
y_test_predictions_mod6 <- predict(mod6, newdata=test)
#Variable importance
importance(mod6)
varImpPlot(mod6, type=1) #Plot the Random Forest Results
dev.copy(png,'mod6_importance.png')
dev.off()
p <- 5
RMSPE <- matrix(0, p, 1)
## Model 1
RMSPE[1] <- sqrt(mean((training$cost_t - y_train_predictions_mod1)^2, na.rm=TRUE))
## Model 2
RMSPE[2] <- sqrt(mean((training$cost_t - y_train_predictions_mod2)^2, na.rm=TRUE))
## Model 3
RMSPE[3] <- sqrt(mean((training$gagne_sum_t - y_train_predictions_mod3)^2, na.rm=TRUE))
## Model 4
RMSPE[4] <- sqrt(mean((training$gagne_sum_t - y_train_predictions_mod4)^2, na.rm=TRUE))
RMSPE[5] <- sqrt(mean((training$cost_avoidable_t - y_train_predictions_mod5)^2, na.rm=TRUE))
RMSPE[6] <- sqrt(mean((training$cost_avoidable_t - y_train_predictions_mod6)^2, na.rm=TRUE))
#Display a table of the results
data.frame(algorithm = c("Model 1 - Costs (excl. race) ",
"Model 2 - Costs (incl. race) ",
"Model 3 - Health (excl. race)",
"Model 4 - Health (incl. race)",
"Model 5 - Avoidable costs (excl. race)",
"Model 6 - Avoidable costs (incl. race)"),
RMSPE)
tinytex::reinstall_tinytex()
p <- 6
RMSPE_OOS <- matrix(0, p, 1)
## Model 1
RMSPE_OOS[1] <- sqrt(mean((test$cost_t - y_test_predictions_mod1)^2, na.rm=TRUE))
## Model 2
RMSPE_OOS[2] <- sqrt(mean((test$cost_t - y_test_predictions_mod2)^2, na.rm=TRUE))
## Model 3
RMSPE_OOS[3] <- sqrt(mean((test$gagne_sum_t - y_test_predictions_mod3)^2, na.rm=TRUE))
## Model 4
RMSPE_OOS[4] <- sqrt(mean((test$gagne_sum_t - y_test_predictions_mod4)^2, na.rm=TRUE))
RMSPE_OOS[5] <- sqrt(mean((test$cost_avoidable_t - y_test_predictions_mod5)^2, na.rm=TRUE))
RMSPE_OOS[6] <- sqrt(mean((test$cost_avoidable_t - y_test_predictions_mod6)^2, na.rm=TRUE))
#Display a table of the results
data.frame(algorithm = c("Model 1 - Costs (excl. race) ",
"Model 2 - Costs (incl. race) ",
"Model 3 - Health (excl. race)",
"Model 4 - Health (incl. race)",
"Model 5 - Avoidable costs (excl. race)",
"Model 6 - Avoidable costs (incl. race)"),
RMSPE_OOS)
#Export data set with training data + predictions from the models
lab8 <- test
lab8$y_test_predictions_mod1 <- y_test_predictions_mod1
lab8$y_test_predictions_mod2 <- y_test_predictions_mod2
lab8$y_test_predictions_mod3 <- y_test_predictions_mod3
lab8$y_test_predictions_mod4 <- y_test_predictions_mod4
lab8$y_test_predictions_mod5 <- y_test_predictions_mod5
lab8$y_test_predictions_mod6 <- y_test_predictions_mod6
write_dta(lab8, "lab8_results.dta")
View(lab8)
View(test)
View(lab8)
lab8$mod1_rank <- percentile_rank(lab8$y_test_predictions_mod1)
lab8$mod2_rank <- percentile_rank(lab8$y_test_predictions_mod2)
lab8$mod3_rank <- percentile_rank(lab8$y_test_predictions_mod3)
lab8$mod4_rank <- percentile_rank(lab8$y_test_predictions_mod4)
lab8$mod5_rank <- percentile_rank(lab8$y_test_predictions_mod5)
lab8$mod6_rank <- percentile_rank(lab8$y_test_predictions_mod6)
percentile_rank <- function(x){
rank <- ifelse(is.na(x), NA, rank(x, ties.method = "average"))
100*rank/max(rank, na.rm=T)
}
lab8$mod1_rank <- percentile_rank(lab8$y_test_predictions_mod1)
lab8$mod2_rank <- percentile_rank(lab8$y_test_predictions_mod2)
lab8$mod3_rank <- percentile_rank(lab8$y_test_predictions_mod3)
lab8$mod4_rank <- percentile_rank(lab8$y_test_predictions_mod4)
lab8$mod5_rank <- percentile_rank(lab8$y_test_predictions_mod5)
lab8$mod6_rank <- percentile_rank(lab8$y_test_predictions_mod6)
View(lab8)
lab8$mod6_rank
dd
ç
;;
22
max(lab8$mod1_rank)
ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point")
library(statar)
ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point")
ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("label")
ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 1 - Costs (excl. race)") + xlab("risk score") + ylab("patient costs")
g1 <- ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 1 - Costs (excl. race)") +
xlab("risk score") + ylab("patient costs")
g2 <- ggplot(lab8, aes(x = mod2_rank , y = cost_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 2 - Costs (incl. race)") +
xlab("risk score") + ylab("patient costs")
g1 <- ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 1 - Costs (excl. race)") +
xlab("risk score") + ylab("patient costs")
g2 <- ggplot(lab8, aes(x = mod2_rank , y = cost_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 2 - Costs (incl. race)") +
xlab("risk score") + ylab("patient costs")
g3 <- ggplot(lab8, aes(x = mod3_rank , y = gagne_sum_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 4 - Health (excl. race)") +
xlab("risk score") + ylab("patient health")
g4 <- ggplot(lab8, aes(x = mod4_rank , y = gagne_sum_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 4 - Health (incl. race)") +
xlab("risk score") + ylab("patient health")
g1 <- ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = white)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 1 - Costs (excl. race)") +
xlab("risk score") + ylab("patient costs")
ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = white)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 1 - Costs (excl. race)") +
xlab("risk score") + ylab("patient costs")
ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = white)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 1 - Costs (excl. race)") +
xlab("risk score") + ylab("patient costs")
ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = race$white)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 1 - Costs (excl. race)") +
xlab("risk score") + ylab("patient costs")
g1 <- ggplot(lab8, aes(x = mod1_rank , y = cost_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 1 - Costs (excl. race)") +
xlab("risk score") + ylab("patient costs")
g2 <- ggplot(lab8, aes(x = mod2_rank , y = cost_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 2 - Costs (incl. race)") +
xlab("risk score") + ylab("patient costs")
g3 <- ggplot(lab8, aes(x = mod3_rank , y = gagne_sum_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 3 - Health (excl. race)") +
xlab("risk score") + ylab("patient health")
g4 <- ggplot(lab8, aes(x = mod4_rank , y = gagne_sum_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 4 - Health (incl. race)") +
xlab("risk score") + ylab("patient health")
g5 <- ggplot(lab8, aes(x = mod5_rank , y = cost_avoidable_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 5 - Avoidable Costs (excl. race)") +
xlab("risk score") + ylab("patient avoidable costs")
g6 <- ggplot(lab8, aes(x = mod6_rank , y = cost_avoidable_t, color = race)) +
stat_binmean(n = 20, geom = "line") +
stat_binmean(n = 20, geom = "point") + ggtitle("Model 6 - Avoidable Costs (incl. race)") +
xlab("risk score") + ylab("patient avoidable costs")
ggsave(g1, "g1.png")
d
ggsave("g1.png", plot=g1)
ggsave("g1.png", plot=g1)
ggsave("g1.png", plot=g1)
View(mod2)
ggsave("g1.png", plot=g1)
ggsave("g2.png", plot=g2)
ggsave("g3.png", plot=g3)
ggsave("g4.png", plot=g4)
ggsave("g5.png", plot=g5)
ggsave("g6.png", plot=g6)
?nrows
fraction_q7a_1 <- nrow(lab8[mod1_rank > .55 && race == "black"])/nrow(lab8[mod1_rank > .55 && race == "black"])
fraction_q7a_1 <- nrow(lab8[lab8$mod1_rank > .55 && lab8$race == "black"])/nrow(lab8[lab8$mod1_rank > .55 && lab8$race == "black"])
fraction_q7a_1 <- nrow(lab8[lab8$mod1_rank > .55 && lab8$race == "black"])/nrow(lab8[lab8$race == "black"])
fraction_q7a_1 <- nrow(lab8[lab8$mod1_rank > .55 && lab8$race == "black"])/nrow(lab8[lab8$race == "black"])
nrow(lab8[lab8$race == "black"])
nrow(lab8[race == "black"])
fraction_q7a_1 <- nrow(lab8[lab8$mod1_rank > .55 && lab8$race == "black"])/nrow(lab8[race == "black"])
nrow(lab8[lab8$mod1_rank > .55 && lab8$race == "black"])
nrow(lab8[lab8$mod1_rank > .55])
nrow(lab8[mod1_rank > .55])
